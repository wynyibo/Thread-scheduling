OpenMP是一个支持多平台共享内存并行编程的API，它提供了多种机制来实现数据并行，其中包括最常用的`parallel loop`（并行循环）和`SIMD`（单指令多数据）指令。以下是这些概念以及调度相关的背景知识：

## Parallel Loop（并行循环）

在OpenMP中，`parallel loop`是指使用`parallel for`指令来并行化一个循环。这种并行化方法允许循环的迭代在不同的线程上同时执行，从而提高程序的执行效率。

### 背景知识：

* **自动并行化**：编译器自动识别循环的迭代之间是否存在依赖关系，如果不存在或者依赖关系可以忽略，则可以自动进行并行化。
* **并行区域**：通过`parallel for`指令定义的循环区域，每个线程独立执行循环的一部分迭代。
* **线程数**：OpenMP会根据系统的硬件资源和当前的负载情况自动决定使用的线程数，但开发者也可以通过设置环境变量或使用API来指定线程数。

### 编写要领：

* 找到计算密集型的循环；
* 使循环迭代独立，使它们可以安全地以任何顺序执行，而无需循环依赖项；
* 使用适当的OpenMP指令并测试
* 循环必须是**单入口、单出口**，循环内部不允许能够达到循环以外的跳转语句(exit除外)。异常的处理也必须在循环体内处理。例如：若循环体内的break或goto会跳转到循环体外，那么会编译不通过。

```c
#include <omp.h>
#include <stdio.h>
int main(int argc, char *argv[])
{
    const int N = 1000;
    double A[N];
#pragma omp parallel
    {
#pragma omp for
        for (int i = 0; i < N; ++i)
            A[i] = i * i;
    }
    return 0;
}
```

## SIMD（单指令多数据）

`SIMD`是指利用现代处理器中的单指令多数据流（SIMD）架构，通过一条指令同时对多个数据执行相同的操作。OpenMP通过`simd`指令来支持这种并行性。

### 背景知识：

* **向量指令**：SIMD指令通常是由处理器提供的向量指令集，如Intel的SSE、AVX，ARM的NEON等。
* **数据并行**：`simd`指令允许在数据级并行，即在一条指令中处理多个数据元素，这适用于对数组或集合中的元素执行相同的操作。
* **编译器支持**：并不是所有的循环都可以自动转换为SIMD形式，编译器需要在保证数据依赖性的前提下，将循环体中的操作转换为适合SIMD处理的格式。

## 调度相关

调度是指如何将循环的迭代分配给各个线程执行的过程。OpenMP提供了多种调度策略来优化性能。

### 背景知识：

* **静态调度**：在循环开始之前，所有的迭代都被预先分配给各个线程。这种方法简单，但可能导致负载不平衡。
* **动态调度**：在循环执行过程中，迭代动态地分配给空闲的线程。这种方法可以更好地处理循环迭代之间的工作负载不平衡。
* **guided调度**：这是一种特殊的动态调度，它首先以较大的步长分配迭代，然后逐步减少步长，以平衡线程之间的负载。
* **runtime调度**：允许在运行时根据当前系统的状态选择最合适的调度策略。
  通过合理选择调度策略，开发者可以优化程序的性能，减少线程间的通信和同步开销，提高并行执行的效率。

```c
#pragma omp parallel shared (a, b) private (i)
#pragma omp for schedule(static)
for(i=0;i<N;i++) {
   a[i] = a[i] + b[i];
}
```